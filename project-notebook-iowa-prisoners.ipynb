{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Submission\n",
    "* Student name: James M. Irivng, Ph.D.\n",
    "* Student pace: full time\n",
    "* Scheduled project review date/time: 05/15/19 2:30 pm\n",
    "* Instructor name: Jeff Herman / Brandon Lewis\n",
    "* Blog post URL:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iowa Prisoner Recidivism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/iowa_in_jail.png\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/LSA_map_with_counties_districts_and_B54A5BBCE4156.jpg\" width=300px>\n",
    "\n",
    "- The state of Iowa has had a prisoner recidivism issue that has become an increasing problem over several decades, with recidivism rates over 35% in 2007-2009.  While there was a period of gradual reduction from 2010-2014, there was a major jump in recidivism in 2015-2016.\n",
    "<img src=\"images/recidivism_report_1.png\" width=400px>\n",
    "\n",
    "- In 2015, US Dept. of Justice gave Iowa a $3 million Grant to help reduce recividism. At the time, 31.9% of  all released prisoners from Iowa were returning to prison within 3 years of being released.\n",
    "Despite this investment, the recidivism rate has continued to clime, reaching 36% by 2018.\n",
    "\n",
    "\n",
    "<img src=\"images/recidivism_report_2.png\" width=400px>\n",
    "\n",
    "- *Recidivism statistics and visualizations above are from the [Iowa Department of Corrections Annual Report 2018](https://doc.iowa.gov/document/fy-2018-corrections-annual-report)*\n",
    "\n",
    "\n",
    "\n",
    "- In order the better address the increase in prisoner recidivism, the Iowa State Department of Corrections has released data regarding which prisoners return to jail within 3 years of release, in the hopes of finding insights for areas of possible intervention.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our goal for this analysis was two-fold: \n",
    "    1. Build a machine learning model that could predict which released prisoners will become recidivists/return-to-prison within 3 years of release.\n",
    "    2. To identify which of the prisoner's demographics/features best predicts/explains which prisoners become recidivists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Source: Iowa Department of Corrections "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Source: \n",
    "    - https://www.kaggle.com/slonnadube/recidivism-for-offenders-released-from-prison\n",
    "- Original/Up-to-date Source: \n",
    "    - https://data.iowa.gov/Correctional-System/3-Year-Recidivism-for-Offenders-Released-from-Pris/mw8r-vqy4\n",
    "- **Statistics about recidivism in prisoners from a 3 year prisoner**\n",
    "\n",
    "#### **Target:**\n",
    "- Recidivism - Return to Prison\n",
    "    - No = No Recidivism; \n",
    "    - Yes = Prison admission for any reason within the 3-year tracking period\n",
    "\n",
    "#### **Features:**\n",
    "<!--     - Fiscal Year Released\n",
    "    - Recidivism Reporting Year\n",
    "    - Race - Ethnicity\n",
    "    - Age At Release\n",
    "    - Convicting Offense Classification\n",
    "    - Convicting Offense Type\n",
    "    - Convicting Offense Subtype\n",
    "    - Main Supervising District\n",
    "    - Release Type\n",
    "    - Release type: Paroled to Detainder united\n",
    "    - Part of Target Population -->\n",
    "\n",
    "- ~~**Fiscal Year Released**~~ [Not used in model]\n",
    "    - Fiscal year (year ending June 30) for which the offender was released from prison.\n",
    "\n",
    "- ~~**Recidivism Reporting Year**~~ [Not used in model]\n",
    "    - Fiscal year (year ending June 30) that marks the end of the 3-year tracking period. For example, offenders exited prison in FY 2012 are found in recidivism reporting year FY 2015.\n",
    "\n",
    "- **Race - Ethnicity**\n",
    "    - Offender's Race and Ethnicity\n",
    "\n",
    "- **Convicting Offense Classification**\n",
    "    - Maximum penalties: A Felony = Life; B Felony = 25 or 50 years; C Felony = 10 years; D Felony = 5 years; Aggravated Misdemeanor = 2 years; Serious Misdemeanor = 1 year; Simple Misdemeanor = 30 days\n",
    "\n",
    "- **Convicting Offense Type**\n",
    "    - General category for the most serious offense for which the offender was placed in prison.\n",
    "\n",
    "- **Convicting Offense Subtype**\n",
    "    - Further classification of the most serious offense for which the offender was placed in prison.\n",
    "\n",
    "- **Release Type**\n",
    "    - Reasoning for Offender's release from prison.\n",
    "\n",
    "- **Main Supervising District**\n",
    "    - The Judicial District supervising the offender for the longest time during the tracking period.\n",
    "\n",
    "\n",
    "- **Part of Target Population** \n",
    "    - The Department of Corrections has undertaken specific strategies to reduce recidivism rates for prisoners who are on parole and are part of the target population.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USING THE OSEMN MODEL TO GUIDE WORKFLOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **OBTAIN:**\n",
    "    - [x] Import data, inspect, check for datatypes to convert and null values\n",
    "<br><br>\n",
    "\n",
    "2. **SCRUB: cast data types, identify outliers, check for multicollinearity, normalize data**<br>\n",
    "    - Check and cast data types\n",
    "    - [x] Check for missing values \n",
    "    - [x] Check for multicollinearity\n",
    "    - [x] Normalize data (may want to do after some exploring)   \n",
    "    <br><br>\n",
    "            \n",
    "3. **EXPLORE:Check distributions, outliers, etc**\n",
    "    - [x] Check scales, ranges (df.describe())\n",
    "    - [x] Check histograms to get an idea of distributions (df.hist()) and data transformations to perform\n",
    "    - [x] Use scatterplots to check for linearity and possible categorical variables (df.plot(kind-'scatter')\n",
    "    <br><br>\n",
    "\n",
    "   \n",
    "4. **FIT AN INITIAL MODEL:** \n",
    "    - [x] Assess the model.\n",
    "        <br><br>\n",
    "5. **REVISE THE FITTED MODEL**\n",
    "    - [x] Adjust chosen model and hyper-parameters\n",
    "    <br><br>\n",
    "6. **HOLDOUT VALIDATION**\n",
    "    - [ ] Perform cross-validation\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBTAIN:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Custom PyPi Package - `fsds`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:37:05.099665Z",
     "start_time": "2021-08-07T18:37:03.386599Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -U fsds\n",
    "from fsds.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:37:05.148534Z",
     "start_time": "2021-08-07T18:37:05.101462Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import bs_ds_local as bs\n",
    "import project_functions as ji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T19:08:26.657204Z",
     "start_time": "2021-08-07T19:08:26.589661Z"
    }
   },
   "outputs": [],
   "source": [
    "# %conda install -c conda-forge shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T19:08:30.435071Z",
     "start_time": "2021-08-07T19:08:28.687670Z"
    }
   },
   "outputs": [],
   "source": [
    "## Set Pandas Options\n",
    "import pandas as pd\n",
    "# pd.set_eng_float_format(accuracy=2)\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.2f}')\n",
    "pd_options = {\n",
    "    'display.max_rows'    : 200,\n",
    "    'display.max_info_rows':200,\n",
    "    'display.max_columns' : 0,\n",
    "}\n",
    "[pd.set_option(option, setting) for option, setting in pd_options.items()]\n",
    "\n",
    "## Visualization Packages and Settings\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import missingno as ms\n",
    "\n",
    "\n",
    "## Set Plot Style\n",
    "plt.style.use('fivethirtyeight')\n",
    "# sns.set_context(font_scale=2)\n",
    "\n",
    "## Suppress Warnings\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "## version check\n",
    "import sklearn\n",
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "print(f\"Matplotlib Version: {mpl.__version__}\")\n",
    "print(f\"Scikit-learn Version: {sklearn.__version__}\")\n",
    "print(f\"Pandas Version: {pd.__version__}\")\n",
    "print(f\"Numpy Version: {np.__version__}\")\n",
    "print(f\"Seaborn Version: {sns.__version__}\")\n",
    "print(f\"Shap Version: {shap.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:37:14.907120Z",
     "start_time": "2021-08-07T18:37:14.875657Z"
    }
   },
   "outputs": [],
   "source": [
    "## Reducing Random Variations\n",
    "SEED = 321\n",
    "np.random.seed(321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing & Modeling Imports\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import (StandardScaler, MinMaxScaler,RobustScaler,\n",
    "                                   OneHotEncoder)\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier,StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  PROJECT CONTROL BOOLEAN ARGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:52.503920Z",
     "start_time": "2021-08-07T18:35:52.474609Z"
    }
   },
   "outputs": [],
   "source": [
    "### PROJECT CONTROL BOOLS\n",
    "\n",
    "## 1. Data Source\n",
    "# Control if data downloaded fresh from Iowa gov api or original kaggle versin\n",
    "USE_ORIG_DATA = False \n",
    "\n",
    "## if USE_ORIG_DATA==False, download new csv from API or use previous downloaded\n",
    "GET_NEW_DATA = False\n",
    "\n",
    "if USE_ORIG_DATA==True &  GET_NEW_DATA==True:\n",
    "    raise Exception('Only one of [USE_ORIG_DATA, GET_NEW_DATA] may be True')\n",
    "\n",
    "## 2. Gridsearches\n",
    "# Control if run new gridsearch or use previous params\n",
    "RUN_SEARCHES = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset and removing unrelated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:52.575012Z",
     "start_time": "2021-08-07T18:35:52.505968Z"
    }
   },
   "outputs": [],
   "source": [
    "## Set project booleans above to change data source used\n",
    "if USE_ORIG_DATA:\n",
    "    file = 'data/3-Year_Recidivism_for_Offenders_Released_from_Prison_in_Iowa.csv'\n",
    "    print(f'Using original data: {file}')\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    ## Making snake case column names if using orignal Kaggle dataset\n",
    "    snake_case_cols = [c.lower().strip().replace(' - ',' ').replace(' ','_') for c in df.columns]\n",
    "\n",
    "    ## clean up additional changes made to col names\n",
    "    list_of_updates = [('classification','class'),\n",
    "                       ('days_to_return','days_return'),\n",
    "                      ('sub_type','subtype')]\n",
    "    ## Fix changes in naming scheme\n",
    "    for current,new in list_of_updates:\n",
    "        snake_case_cols =[c.replace(current,new) for c in snake_case_cols]\n",
    "    \n",
    "    ## Make a renaming map and rename columns\n",
    "    column_names_map = dict(zip(df.columns,snake_case_cols))\n",
    "    df.rename(column_names_map,axis=1,inplace=True)\n",
    "    \n",
    "elif GET_NEW_DATA:\n",
    "    url = \"https://data.iowa.gov/resource/mw8r-vqy4.csv\"\n",
    "    print(f'Downloading data from API: {url}')\n",
    "    df = pd.read_csv(url)\n",
    "    \n",
    "    new_file = \"data/iowa-prisoner-recidivism_data-iowa-gov-api.csv\"\n",
    "    df.to_csv(new_file,index=False)\n",
    "    print(f\"- downloaded data saved as: {new_file}\")\n",
    "\n",
    "else:\n",
    "    file = \"data/iowa-prisoner-recidivism_data-iowa-gov-api.csv\"\n",
    "    df = pd.read_csv(file)\n",
    "    print(f'Using preivous api download: {file}' )\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:52.612190Z",
     "start_time": "2021-08-07T18:35:52.577012Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:52.652457Z",
     "start_time": "2021-08-07T18:35:52.613970Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check years included \n",
    "df[[c for c in df.columns if 'year' in c]].agg(['min','max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE ENGINEERING TO-DO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I would like to add more information related to the judicial district. \n",
    "- One approach is to match the Judicial Districts to Counties and map crime/pop data for the county to the district.\n",
    "- List of Counties Served on Ballotpedia:\n",
    "    - https://ballotpedia.org/Iowa_District_Courts\n",
    "- FBI Crime report for 2014:\n",
    "    - https://ucr.fbi.gov/crime-in-the-u.s/2014/preliminary-semiannual-uniform-crime-report-january-june-2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Any columns that are about New Convictions or days to recidivism should be dropped for our initial model predicting recidivism.**\n",
    "- \"New..\", \"Days to Recividism\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:52.688722Z",
     "start_time": "2021-08-07T18:35:52.656619Z"
    }
   },
   "outputs": [],
   "source": [
    "## Drop cols related to recivism details \n",
    "drop_expr = ['new',\"days\",\"recidivism_type\",\"year\"]\n",
    "drop_cols = []\n",
    "for exp in drop_expr:\n",
    "    drop_cols.extend([col for col in df.columns if exp in col])\n",
    "drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:52.737764Z",
     "start_time": "2021-08-07T18:35:52.691653Z"
    }
   },
   "outputs": [],
   "source": [
    "## Saving removed columns to merge again after feature engineering (for tableau)\n",
    "removed_df = df[drop_cols].copy()\n",
    "removed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:52.785497Z",
     "start_time": "2021-08-07T18:35:52.739640Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(columns=drop_cols,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save original names vs short names in column_legend\n",
    "- then map names onto columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:52.816599Z",
     "start_time": "2021-08-07T18:35:52.787252Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Replacing columns with short names\n",
    "# rename_map = {\n",
    "#     'Fiscal Year Released': 'yr_released',\n",
    "#     'Recidivism Reporting Year': 'report_year' ,\n",
    "#     'Main Supervising District': 'supervising_dist' ,\n",
    "#     'Release Type': 'release_type' ,\n",
    "#     'Race - Ethnicity': 'race_ethnicity'  ,\n",
    "#     'Age At Release ':  'age_at_release' ,\n",
    "#     'Sex':'sex'   ,\n",
    "#     'Offense Classification': 'offense_class' ,\n",
    "#     'Offense Type': 'crime_type'  ,\n",
    "#     'Offense Subtype':  'crime_subtype' ,\n",
    "#     'Return to Prison': 'recidivist'  ,\n",
    "#     'Target Population':  'target_pop'\n",
    "# }\n",
    "\n",
    "# df = df.rename(rename_map,axis=1)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:52.855601Z",
     "start_time": "2021-08-07T18:35:52.818575Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('data/iowa_recidivism_renamed_2021.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRUB / EXPLORE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:52.891173Z",
     "start_time": "2021-08-07T18:35:52.857505Z"
    }
   },
   "outputs": [],
   "source": [
    "## Explore Dtypes and info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:52.930437Z",
     "start_time": "2021-08-07T18:35:52.893215Z"
    }
   },
   "outputs": [],
   "source": [
    "import missingno as ms\n",
    "\n",
    "def column_report(df,perc_null_thresh=5,return_report=False):\n",
    "    \"\"\"Returns a dataframe with the following summary information\n",
    "    for each column in df.\n",
    "    - Dtype\n",
    "    - # Unique Entries\n",
    "    - # Null Values\n",
    "    - # Non-Null Values\n",
    "    - % Null Values\n",
    "    \"\"\"\n",
    "    report = pd.DataFrame({\n",
    "        'nunique':df.nunique(),\n",
    "        'dtype':df.dtypes, \n",
    "        '# Non-Null': df.notnull().sum(),\n",
    "        '# Nulls': df.isna().sum(),\n",
    "        '% Nulls':df.isna().sum()/len(df)*100,\n",
    "        })\n",
    "    \n",
    "    report = report.reset_index().rename({'index':'column'},axis=1)\n",
    "    \n",
    "    if return_report:\n",
    "        return report#.round(2)    \n",
    "    else:\n",
    "        def style_nulls(v, thresh=perc_null_thresh, props=''):\n",
    "            return props if v > thresh else None\n",
    "        s2 = report.style.applymap(style_nulls, props='color:red;',subset=['% Nulls'])\\\n",
    "                        .format(lambda x: f\"{x:.2f} %\",subset=['% Nulls'])\\\n",
    "                        .set_caption(\"Column Report\")\n",
    "        display(s2)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def nulls_report(df,plot=True):\n",
    "    \"\"\"Displays a series of null values for any columns with >0 nulls\"\"\"\n",
    "    nulls= df.isna().sum()\n",
    "    nulls_only = nulls[nulls>0]\n",
    "    nulls_only = nulls_only.round(2)\n",
    "    \n",
    "    \n",
    "    if plot:\n",
    "        with plt.style.context('seaborn-poster'):\n",
    "            ms.matrix(df,figsize=(10,4))\n",
    "            plt.show()\n",
    "        \n",
    "    print('Columns with Null Values:')\n",
    "    display(nulls_only)#.style.format(lambda x: f\"{x:.2f} %\",\n",
    "#                                                       subset=['%']))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:53.220861Z",
     "start_time": "2021-08-07T18:35:52.932288Z"
    }
   },
   "outputs": [],
   "source": [
    "nulls_report(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results of Null Check**\n",
    "<!-- - race_ethnicity has 30 (0.12% of data)\n",
    "    -  drop\n",
    "- age_at_release has 3 (0.01% of data)\n",
    "    - drop\n",
    "- sex has 3 (0.01% of data)\n",
    "    - drop -->\n",
    "- main_supervising_district has 9581(36.82% of data)\n",
    "    - replace with \"unknown\"\n",
    "- release_type has 1762 (6.77% of data)\n",
    "    - drop\n",
    "    \n",
    "**Dropping all null values from age_at_release, race_ethnicity, and release_type.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:53.267120Z",
     "start_time": "2021-08-07T18:35:53.222609Z"
    }
   },
   "outputs": [],
   "source": [
    "    \n",
    "column_report(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:53.300546Z",
     "start_time": "2021-08-07T18:35:53.269160Z"
    }
   },
   "outputs": [],
   "source": [
    "def value_counts(col,dropna=False,normalize=True,sort_index=False,rename=True):\n",
    "    \"\"\"Convenience function for display value counts with default params\"\"\"\n",
    "    counts =  col.value_counts(dropna=dropna,normalize=normalize)\n",
    "    if sort_index:\n",
    "        counts.sort_index(inplace=True)\n",
    "        \n",
    "    if rename:\n",
    "        counts.name=f'{counts.name}.value_counts(normalized={normalize}, dropna={dropna})'\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:53.362957Z",
     "start_time": "2021-08-07T18:35:53.302474Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## inspect categories\n",
    "dashes = '---'*20\n",
    "for col in df.columns:\n",
    "    print(dashes)\n",
    "    print(f\"Value Counts for {col}:\")\n",
    "    display(value_counts(df[col],normalize=False,rename=False))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- convert age_at_release to numeric\n",
    "- Convert return_to_prison and 'target_population' to 0,1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIMPLIFYING CATEGORICAL FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use Rare Label Encoding on high cardinality columns:\n",
    "    - `offsense_subtype`\n",
    "- Replace bins with numeric values:\n",
    "    - `age_at_release`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:53.398142Z",
     "start_time": "2021-08-07T18:35:53.364729Z"
    }
   },
   "outputs": [],
   "source": [
    "# col = 'offense_subtype'\n",
    "# ax = df[col].value_counts(1).plot(kind='bar',figsize=(8,4))\n",
    "# ax.set(ylabel='% of Observations',xlabel='Category',\n",
    "#        title=f'Value Counts for {col}')\n",
    "# ax.axhline(.05,c='red',label='5% cutoff')\n",
    "# ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:53.430900Z",
     "start_time": "2021-08-07T18:35:53.400021Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_rare_labels(df,col = 'offense_subtype',\n",
    "                     thresh=.01,report=True):\n",
    "    \n",
    "    ## PLot value counts\n",
    "    counts = df[col].value_counts(1)\n",
    "    \n",
    "    ax = counts.plot(kind='bar',figsize=(8,4))\n",
    "    ax.set(ylabel='% of Observations',xlabel='Category',\n",
    "           title=f'Value Counts for {col}')\n",
    "    ax.axhline(thresh,c='red',label=f'{thresh*100:.2f}% cutoff')\n",
    "    ax.legend();\n",
    "    \n",
    "    ## get list of rare/non-rare\n",
    "    rare = counts[counts<thresh]\n",
    "    if report:\n",
    "        plt.show()\n",
    "        \n",
    "        if len(rare)>0:\n",
    "            print(f'[i] Rare Labels Present in {col}:')\n",
    "            print(rare)\n",
    "        else:\n",
    "            print(f'[i] No Rare Labels Present in {col}.')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:53.788021Z",
     "start_time": "2021-08-07T18:35:53.432785Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_rare_labels(df,col='offense_subtype',thresh=0.01);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making `age_at_release` numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:53.820108Z",
     "start_time": "2021-08-07T18:35:53.789624Z"
    }
   },
   "outputs": [],
   "source": [
    "value_counts(df['age_at_release'])#.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:54.099763Z",
     "start_time": "2021-08-07T18:35:53.826677Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_rare_labels(df,'age_at_release')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:54.141270Z",
     "start_time": "2021-08-07T18:35:54.105818Z"
    }
   },
   "outputs": [],
   "source": [
    "# converting age to numeric feature\n",
    "age_num_map = {'Under 25':20,\n",
    "              '25-34':30, \n",
    "              '35-44':40,\n",
    "              '45-54':50,\n",
    "              '55 and Older':70}\n",
    "df['age_at_release'] = df['age_at_release'].map(age_num_map)\n",
    "value_counts(df['age_at_release'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df['race_ethnicity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:54.174893Z",
     "start_time": "2021-08-07T18:35:54.143114Z"
    }
   },
   "outputs": [],
   "source": [
    "value_counts(df['race_ethnicity'],normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Remapping race_ethnicity**\n",
    "    - Due to the low numbers for several of the race_ethnicity types, reducing and combining Hispanic and Non-Hispanic groups\n",
    "    - Alternative approach of separating race and ethnicity into 2 separate features was rejected after modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:54.206315Z",
     "start_time": "2021-08-07T18:35:54.176776Z"
    }
   },
   "outputs": [],
   "source": [
    "# df['race_ethnicity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:54.243014Z",
     "start_time": "2021-08-07T18:35:54.208459Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining Dictionary Map for race_ethnicity categories\n",
    "\n",
    "# race_ethnicity_map = {'White - Non-Hispanic':'White',\n",
    "#                         'Black - Non-Hispanic': 'Black',\n",
    "#                         'White - Hispanic' : 'Hispanic',\n",
    "#                         'American Indian or Alaska Native - Non-Hispanic' : 'American Native',\n",
    "#                         'Asian or Pacific Islander - Non-Hispanic' : 'Asian or Pacific Islander',\n",
    "#                         'Black - Hispanic' : 'Black',\n",
    "#                         'American Indian or Alaska Native - Hispanic':'American Native',\n",
    "#                         'White -' : 'White',\n",
    "#                         'Asian or Pacific Islander - Hispanic' : 'Asian or Pacific Islander',\n",
    "#                         'N/A -' : np.nan,\n",
    "#                         'Black -':'Black'}\n",
    "\n",
    "race_ethnicity_renamer = {'White -':'White - Non-Hispanic'}\n",
    "\n",
    "# Replacing original race_ethnicity column with remapped one.\n",
    "df['race_ethnicity'] = df['race_ethnicity'].replace(race_ethnicity_renamer)\n",
    "value_counts(df['race_ethnicity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:54.488289Z",
     "start_time": "2021-08-07T18:35:54.244928Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_rare_labels(df,'race_ethnicity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df['offense_class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Remapping offense_class**\n",
    "    - Combine 'Other Felony' and 'Other Felony (Old Code)' -> nan\n",
    "    - Other Misdemeanor -> np.nan\n",
    "    - Felony - Mandatory Minimum -> np.nan\n",
    "    - Special Sentence 2005 -> Sex Offender\n",
    "    - 'Sexual Predator Community Supervision' -> 'Sex Offender'\n",
    "    - Other Felony -> np.nan    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:54.520966Z",
     "start_time": "2021-08-07T18:35:54.490043Z"
    }
   },
   "outputs": [],
   "source": [
    "value_counts(df['offense_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:54.554928Z",
     "start_time": "2021-08-07T18:35:54.522718Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remapping\n",
    "offense_class_map = {'Other Felony (Old Code)':'Other Felony' ,#or other felony\n",
    "                  'Other Misdemeanor':'Other Misdemeanor',\n",
    "                   'Felony - Mandatory Minimum':'Other Felony',#np.nan, # if minimum then lowest sentence ==  D Felony\n",
    "                   'Special Sentence 2005': 'Sex Offender',\n",
    "                   'Other Felony' : 'Other Felony' ,\n",
    "                   'Sexual Predator Community Supervision' : 'Sex Offender',\n",
    "                   'D Felony': 'D Felony',\n",
    "                   'C Felony' :'C Felony',\n",
    "                   'B Felony' : 'B Felony',\n",
    "                   'A Felony' : 'A Felony',\n",
    "                   'Aggravated Misdemeanor':'Aggravated Misdemeanor',\n",
    "                   'Felony - Enhancement to Original Penalty':'Felony - Enhanced',\n",
    "                   'Felony - Enhanced':'Felony - Enhanced' ,\n",
    "                   'Serious Misdemeanor':'Serious Misdemeanor',\n",
    "                   'Simple Misdemeanor':'Simple Misdemeanor'}\n",
    "\n",
    "df['offense_class'] = df['offense_class'].map(offense_class_map)\n",
    "value_counts(df['offense_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:54.584722Z",
     "start_time": "2021-08-07T18:35:54.556870Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot_rare_labels(df, 'offense_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:54.841508Z",
     "start_time": "2021-08-07T18:35:54.586499Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_rare_labels(df,'offense_class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remapping Binary Cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:54.874114Z",
     "start_time": "2021-08-07T18:35:54.843571Z"
    }
   },
   "outputs": [],
   "source": [
    "binary_cols = df.columns[df.nunique()==2]\n",
    "binary_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'sex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:54.905848Z",
     "start_time": "2021-08-07T18:35:54.876149Z"
    }
   },
   "outputs": [],
   "source": [
    "sex_map = {'Male':1, 'Female':0}\n",
    "sex_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:54.942277Z",
     "start_time": "2021-08-07T18:35:54.907617Z"
    }
   },
   "outputs": [],
   "source": [
    "df['sex'] = df['sex'].replace(sex_map)\n",
    "df['sex'] = df['sex'].astype('category')\n",
    "value_counts(df['sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remapping target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:54.976972Z",
     "start_time": "2021-08-07T18:35:54.944213Z"
    }
   },
   "outputs": [],
   "source": [
    "value_counts(df['return_to_prison'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:55.012591Z",
     "start_time": "2021-08-07T18:35:54.978801Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Recidivist\n",
    "target_map = {'No':0,'Yes':1}\n",
    "df['return_to_prison'] = df['return_to_prison'].map(target_map)\n",
    "value_counts(df['return_to_prison'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T17:42:08.116753Z",
     "start_time": "2021-07-10T17:42:08.077105Z"
    }
   },
   "source": [
    "#### `target_pop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:55.046651Z",
     "start_time": "2021-08-07T18:35:55.014452Z"
    }
   },
   "outputs": [],
   "source": [
    "value_counts(df['target_population'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:55.082463Z",
     "start_time": "2021-08-07T18:35:55.048450Z"
    }
   },
   "outputs": [],
   "source": [
    "df['target_population'] = df['target_population'].map( {'No':0,'Yes':1}).astype('category')\n",
    "value_counts(df['target_population'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## FEATURE ENGINEERING\n",
    "- **Engineering a simple 'felony' true false category**\n",
    "- **Combining crime_type and crime_subtype into types_combined**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a simple 'felony' feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:55.120045Z",
     "start_time": "2021-08-07T18:35:55.084157Z"
    }
   },
   "outputs": [],
   "source": [
    "# Engineering a simple 'felony' true false category\n",
    "df['felony'] = df['offense_class'].str.contains('felony',case=False).astype('category')\n",
    "value_counts(df['felony'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:55.153692Z",
     "start_time": "2021-08-07T18:35:55.121907Z"
    }
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:55.207810Z",
     "start_time": "2021-08-07T18:35:55.155449Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:55.242957Z",
     "start_time": "2021-08-07T18:35:55.209549Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combining crime_type and crime_subtype into types_combined\n",
    "# df['offense_class_type_subtype']= df['offense_class']+'_'+df['offense_class']+'_'+df['offense_subtype']\n",
    "# value_counts(df['offense_class_type_subtype'])\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a 'max_sentence' feature based on crime class max penalties\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:55.276929Z",
     "start_time": "2021-08-07T18:35:55.244741Z"
    }
   },
   "outputs": [],
   "source": [
    "value_counts(df['offense_class']).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unsure what Other Felony might represent. Will assume its halfway between C and D penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T17:07:58.639295Z",
     "start_time": "2021-07-18T17:07:58.606904Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:55.313648Z",
     "start_time": "2021-08-07T18:35:55.278783Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mapping years onto crime class\n",
    "offense_class_max_sentence_map = {'A Felony': 100,  # Life\n",
    "                                'Aggravated Misdemeanor': 2, # 2 years\n",
    "                                'B Felony': 25, # 25 or 50 years\n",
    "                                'C Felony': 10, # 10 years\n",
    "                                'D Felony': 5,  # 5 yeras\n",
    "                                  'Other Felony': 7,\n",
    "                                'Felony - Enhanced': 10, # Add on to class C and D felonies, hard to approximate. \n",
    "                                'Serious Misdemeanor': 1, # 1 year\n",
    "                                'Sex Offender': 10, # 10 years\n",
    "                                'Simple Misdemeanor': 30/365} # 30 days\n",
    "\n",
    "# Mapping max_sentence_column\n",
    "df['max_sentence'] =df['offense_class'].map(offense_class_max_sentence_map)\n",
    "value_counts(df['max_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:55.528804Z",
     "start_time": "2021-08-07T18:35:55.315585Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.histplot(df['max_sentence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Null Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:55.855416Z",
     "start_time": "2021-08-07T18:35:55.530699Z"
    }
   },
   "outputs": [],
   "source": [
    "nulls_report(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing with  Pipelines and ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:44:30.383573Z",
     "start_time": "2021-08-07T18:44:30.327891Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import Pipeline,make_pipeline\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.preprocessing import (StandardScaler, MinMaxScaler,RobustScaler,\n",
    "#                                    OneHotEncoder)\n",
    "\n",
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:56.035664Z",
     "start_time": "2021-08-07T18:35:55.998698Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:56.077520Z",
     "start_time": "2021-08-07T18:35:56.038153Z"
    }
   },
   "outputs": [],
   "source": [
    "## Make x and y\n",
    "target = 'return_to_prison'\n",
    "X = df.drop(columns=target).copy()\n",
    "y = df[target].copy()#.map( {'No':0,'Yes':1})\n",
    "value_counts(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:56.119695Z",
     "start_time": "2021-08-07T18:35:56.079802Z"
    }
   },
   "outputs": [],
   "source": [
    "## Binary columns\n",
    "X.columns[X.nunique() == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:56.158323Z",
     "start_time": "2021-08-07T18:35:56.121887Z"
    }
   },
   "outputs": [],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:56.223874Z",
     "start_time": "2021-08-07T18:35:56.160261Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,\n",
    "                                                    random_state=SEED)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plan is to make 1 ColumnTransformer without scaling, then to add scaling as a step in a modeling pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:56.264177Z",
     "start_time": "2021-08-07T18:35:56.225925Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:56.303725Z",
     "start_time": "2021-08-07T18:35:56.266034Z"
    }
   },
   "outputs": [],
   "source": [
    "## \n",
    "binary_cols = X_train.select_dtypes('category').columns\n",
    "binary_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:56.343035Z",
     "start_time": "2021-08-07T18:35:56.305877Z"
    }
   },
   "outputs": [],
   "source": [
    "## categotical columns to encode\n",
    "cat_cols = list(X_train.select_dtypes('object').columns)\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:56.382729Z",
     "start_time": "2021-08-07T18:35:56.344777Z"
    }
   },
   "outputs": [],
   "source": [
    "## Get a list of columns to be run as numeric data\n",
    "num_cols = X_train.select_dtypes('number').columns\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:56.420663Z",
     "start_time": "2021-08-07T18:35:56.384582Z"
    }
   },
   "outputs": [],
   "source": [
    "## make sure no cols missed\n",
    "[c for c in X_train.columns if c not in [*num_cols,*cat_cols,*binary_cols]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:56.460288Z",
     "start_time": "2021-08-07T18:35:56.423152Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import set_config,clone\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:56.501036Z",
     "start_time": "2021-08-07T18:35:56.462776Z"
    }
   },
   "outputs": [],
   "source": [
    "## Make a num_transformer pipeline\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))])\n",
    "num_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:56.537450Z",
     "start_time": "2021-08-07T18:35:56.503333Z"
    }
   },
   "outputs": [],
   "source": [
    "# num_transformer_reg = clone(num_transformer)\n",
    "# num_transformer_reg.steps.append(('scaler',StandardScaler()))\n",
    "# num_transformer_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:56.582597Z",
     "start_time": "2021-08-07T18:35:56.539725Z"
    }
   },
   "outputs": [],
   "source": [
    "## Create a cat_transformer pipeline \n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer',SimpleImputer(strategy='constant',fill_value='MISSING')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore',sparse=False))])#handle_unknown='ignore',\n",
    "cat_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Preprocessing into one ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:56.668160Z",
     "start_time": "2021-08-07T18:35:56.585233Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## COMBINE BOTH PIPELINES INTO ONE WITH COLUMN TRANSFORMER\n",
    "from sklearn.compose import ColumnTransformer\n",
    "preprocessing = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, num_cols),\n",
    "    ('binary','passthrough',binary_cols),\n",
    "    ('cat', cat_transformer, cat_cols)\n",
    "])\n",
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:56.704027Z",
     "start_time": "2021-08-07T18:35:56.669926Z"
    }
   },
   "outputs": [],
   "source": [
    "# preprocessing_reg = ColumnTransformer(transformers=[\n",
    "#     ('num',num_transformer_reg,num_cols),\n",
    "#     ('cat',cat_transformer,cat_cols),\n",
    "#     ])\n",
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:56.755994Z",
     "start_time": "2021-08-07T18:35:56.705928Z"
    }
   },
   "outputs": [],
   "source": [
    "## Get X_train and X_test from column transformer\n",
    "preprocessing.fit(X_train,y_train)\n",
    "cat_features = preprocessing.named_transformers_['cat']\\\n",
    "                    .named_steps['encoder'].get_feature_names(cat_cols)\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:56.791637Z",
     "start_time": "2021-08-07T18:35:56.757822Z"
    }
   },
   "outputs": [],
   "source": [
    "## Get full list of features\n",
    "\n",
    "columns = [*num_cols,*binary_cols, *cat_features]\n",
    "len(columns)\n",
    "# columns=[*num_cols,*cat_cols,*encoded_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:56.848689Z",
     "start_time": "2021-08-07T18:35:56.793446Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocessing.transform(X_train).shape,preprocessing.transform(X_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:57.006993Z",
     "start_time": "2021-08-07T18:35:56.864893Z"
    }
   },
   "outputs": [],
   "source": [
    "## Transform X_train/X_test and remake df\n",
    "X_train_tf = pd.DataFrame(preprocessing.transform(X_train),\n",
    "                          columns=columns,index=X_train.index)\n",
    "X_test_tf = pd.DataFrame(preprocessing.transform(X_test),\n",
    "                          columns=columns,index=X_test.index)\n",
    "X_train_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:57.053222Z",
     "start_time": "2021-08-07T18:35:57.013013Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_tf.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **One downside of Pipelines is that its harder to get the individual info we need to re-form our dataset as a df**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:57.094458Z",
     "start_time": "2021-08-07T18:35:57.056074Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "def evaluate_classification(model,X_test,y_test,classes=['Non Recid','Recidivst'],\n",
    "                           normalize='true',cmap='Purples',label='',\n",
    "                           return_report=False):\n",
    "    \"\"\"Accepts an sklearn-compatible classification model + test data \n",
    "    and displays several sklearn.metrics functions: \n",
    "    - classifciation_report\n",
    "    - plot_confusion_matrix\n",
    "    - plot_roc_curve\n",
    "    \"\"\"\n",
    "     \n",
    "    ## Get Predictions\n",
    "    y_hat_test = model.predict(X_test)\n",
    "    \n",
    "    ## Classification Report / Scores \n",
    "    table_header = \"[i] CLASSIFICATION REPORT\"\n",
    "    \n",
    "    ## Add Label if given\n",
    "    if len(label)>0:\n",
    "        table_header += f\":\\t{label}\"\n",
    "        \n",
    "    \n",
    "    ## PRINT CLASSIFICATION REPORT\n",
    "    dashes = '---'*20\n",
    "    print(dashes,table_header,dashes,sep='\\n')\n",
    "\n",
    "    print(metrics.classification_report(y_test,y_hat_test,\n",
    "                                    target_names=classes))\n",
    "    \n",
    "    report = metrics.classification_report(y_test,y_hat_test,\n",
    "                                               target_names=classes,\n",
    "                                          output_dict=True)\n",
    "    print(dashes+\"\\n\\n\")\n",
    "    \n",
    "    \n",
    "\n",
    "    ## MAKE FIGURE\n",
    "    fig, axes = plt.subplots(figsize=(10,4),ncols=2)\n",
    "    \n",
    "    ## Plot Confusion Matrix \n",
    "    metrics.plot_confusion_matrix(model, X_test,y_test,\n",
    "                                  display_labels=classes,\n",
    "                                  normalize=normalize,\n",
    "                                 cmap=cmap,ax=axes[0])\n",
    "    axes[0].set(title='Confusion Matrix')\n",
    "    \n",
    "    ## Plot Roc Curve\n",
    "    roc_plot = metrics.plot_roc_curve(model, X_test, y_test,ax=axes[1])\n",
    "    axes[1].legend()\n",
    "    axes[1].plot([0,1],[0,1],ls=':')\n",
    "    axes[1].grid()\n",
    "    axes[1].set_title('Receiving Operator Characteristic (ROC) Curve') \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    if return_report:\n",
    "        return report #fig,axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:57.560615Z",
     "start_time": "2021-08-07T18:35:57.096301Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy= DummyClassifier(strategy='stratified')\n",
    "dummy.fit(X_train_tf,y_train)\n",
    "evaluate_classification(dummy,X_test_tf,y_test,\n",
    "                       label='Dummy Classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:57.625687Z",
     "start_time": "2021-08-07T18:35:57.563265Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF #1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:58.328167Z",
     "start_time": "2021-08-07T18:35:57.628041Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier,StackingClassifier\n",
    "# from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "\n",
    "## \n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_tf,y_train)\n",
    "\n",
    "\n",
    "ji.evaluate_classification(clf,X_test_tf,y_test,X_train=X_train_tf,\n",
    "                           y_train=y_train,label=\"Vanilla Random Forest\")\n",
    "# evaluate_classification(clf,X_test_tf,y_test,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF- Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:59.133116Z",
     "start_time": "2021-08-07T18:35:58.330468Z"
    }
   },
   "outputs": [],
   "source": [
    "## Making a Pipeline/GridSearch to confirm if scaling makes a diff\n",
    "clf_pipe = Pipeline(steps=[\n",
    "    ('scaler',StandardScaler()), \n",
    "    ('clf',RandomForestClassifier(class_weight='balanced'))\n",
    "     ])\n",
    "clf_pipe.fit(X_train_tf,y_train)\n",
    "\n",
    "\n",
    "ji.evaluate_classification(clf_pipe,X_test_tf,y_test,X_train=X_train_tf,\n",
    "                           y_train=y_train,label=\"Vanilla Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:35:59.173497Z",
     "start_time": "2021-08-07T18:35:59.135227Z"
    }
   },
   "outputs": [],
   "source": [
    "set_config(display='text')\n",
    "clf_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:36:12.966403Z",
     "start_time": "2021-08-07T18:35:59.175711Z"
    }
   },
   "outputs": [],
   "source": [
    "## Gridsearch for scaing and class_weight\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
    "\n",
    "params = {'scaler':['passthrough',StandardScaler(),MinMaxScaler(),RobustScaler()],\n",
    "         'clf__class_weight':[None, 'balanced','balanced_subsample']}\n",
    "grid = GridSearchCV(clf_pipe, params, verbose=True,scoring='recall_macro')\n",
    "\n",
    "grid.fit(X_train_tf,y_train)\n",
    "print(grid.best_params_)\n",
    "ji.evaluate_classification(grid.best_estimator_,X_test_tf,y_test\n",
    "                           ,X_train=X_train_tf, y_train=y_train,\n",
    "                           label=\"GridSearch Best Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:36:13.003422Z",
     "start_time": "2021-08-07T18:36:12.968438Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_feature_importance(clf,X_train_tf,plot=True):\n",
    "    importances = pd.Series(clf.feature_importances_,index=X_train_tf.columns)\n",
    "    return importances.sort_values(ascending=False)\n",
    "\n",
    "def plot_importance(clf,X_train_tf,n=25,figsize=(4,8)):\n",
    "    importances = get_feature_importance(clf,X_train_tf)\n",
    "    ax = importances.sort_values().tail(n).plot(kind='barh',figsize=figsize)\n",
    "    ax.set(title=f\"Top {n} Most Important Features\",xlabel='importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:36:13.332416Z",
     "start_time": "2021-08-07T18:36:13.005739Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_importance(clf, X_test_tf,n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest - `class_weight=\"balanced_subsample\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:36:14.341970Z",
     "start_time": "2021-08-07T18:36:13.334453Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(class_weight='balanced')\n",
    "clf.fit(X_train_tf,y_train)\n",
    "ji.evaluate_classification(clf,X_test_tf,y_test,X_train=X_train_tf,y_train=y_train,\n",
    "                           label= \"Random Forest (class_weight='balanced')\")\n",
    "plot_importance(clf,X_test_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTENC for Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since our dataset contains categorical features, we must use the SMOTENC class from imblearn, instead of the normal SMOTE class. \n",
    "- This class requires an index of categorical features and handles them differently than numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:36:14.383967Z",
     "start_time": "2021-08-07T18:36:14.344019Z"
    }
   },
   "outputs": [],
   "source": [
    "## Getting cat features index\n",
    "cat_col_index = [False for col in num_cols]\n",
    "cat_col_index.extend([True for col in binary_cols])\n",
    "\n",
    "cat_col_index.extend([True for col in cat_features])\n",
    "X_train_tf.columns[cat_col_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎛SMOTENC params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:37:40.073081Z",
     "start_time": "2021-08-07T18:37:39.845012Z"
    }
   },
   "outputs": [],
   "source": [
    "smote = SMOTENC(cat_col_index,random_state=SEED,\n",
    "                k_neighbors=3, n_jobs=-1)\n",
    "\n",
    "X_train_smote,y_train_smote = smote.fit_resample(X_train_tf,y_train)\n",
    "y_train_smote.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:36:15.197577Z",
     "start_time": "2021-08-07T18:36:15.091677Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_smote[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:36:16.181109Z",
     "start_time": "2021-08-07T18:36:15.199467Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()#class_weight='balanced')\n",
    "clf.fit(X_train_smote,y_train_smote)\n",
    "ji.evaluate_classification(clf,X_test_tf,y_test,X_train=X_train_tf,y_train=y_train,\n",
    "                           label='RandomForest - SMOTE')\n",
    "plot_importance(clf,X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T18:36:16.431835Z",
     "start_time": "2021-08-07T18:36:16.183174Z"
    }
   },
   "outputs": [],
   "source": [
    "depths = [tree.get_depth() for tree in clf.estimators_]\n",
    "sns.histplot(depths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "params ={'max_depth':[None,5,7,10,20,30,],\n",
    "         'min_samples_leaf':[1,2,3],\n",
    "         'criterion':['gini','entropy'],        \n",
    "        }\n",
    "\n",
    "\n",
    "grid = GridSearchCV(clf,params,scoring='recall_macro', n_jobs=-1)\n",
    "\n",
    "grid.fit(X_train_smote,y_train_smote)\n",
    "print(grid.best_params_)\n",
    "\n",
    "print(grid.best_score_)\n",
    "evaluate_classification(grid.best_estimator_,X_test_tf,y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.704Z"
    }
   },
   "outputs": [],
   "source": [
    "clf_pipe = Pipeline(steps=[\n",
    "    ('scaler',StandardScaler()), \n",
    "    ('clf',RandomForestClassifier(class_weight='balanced'))\n",
    "     ])\n",
    "\n",
    "params ={'scaler':['passthrough',StandardScaler(),MinMaxScaler()],\n",
    "         'clf__class_weight':['balanced','balanced_subsample'],\n",
    "         'clf__max_depth':[None,30,33,35,37],\n",
    "         'clf__min_samples_leaf':[1,2,3],\n",
    "         'clf__min_samples_split':[2,3],\n",
    "         'clf__criterion':['gini','entropy'], \n",
    "#          'clf__n_estimators':[50,100,150]\n",
    "        }\n",
    "\n",
    "grid = GridSearchCV(clf_pipe, params, verbose=True,\n",
    "                    n_jobs=-1,cv=3,scoring='recall_macro')\n",
    "\n",
    "grid.fit(X_train_tf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.707Z"
    }
   },
   "outputs": [],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "ji.evaluate_classification(grid.best_estimator_,X_test_tf,y_test,\n",
    "                           X_train=X_train_tf,y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Observations/Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forests seem to have a hard time learning about the minority class- Return-to_prison = Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Parameter tuning for xgboost](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.713Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRFClassifier,XGBClassifier\n",
    "import xgboost as xgb\n",
    "xgb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.719Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.723Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_reg = pd.DataFrame(scaler.fit_transform(X_train_tf),\n",
    "                           columns=X_train_tf.columns, index=X_train_tf.index)\n",
    "X_test_reg = pd.DataFrame(scaler.transform(X_test_tf),\n",
    "                          columns=X_train_tf.columns, index=X_test_tf.index)\n",
    "X_train_reg.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.728Z"
    }
   },
   "outputs": [],
   "source": [
    "## Getting cat features index\n",
    "cat_col_index = [False for col in num_cols]\n",
    "cat_col_index.extend([True for col in binary_cols])\n",
    "\n",
    "cat_col_index.extend([True for col in cat_features])\n",
    "\n",
    "smote = SMOTENC(cat_col_index, n_jobs=-1)\n",
    "\n",
    "X_train_reg_smote,y_train_reg_smote = smote.fit_resample(X_train_reg,y_train)\n",
    "y_train_reg_smote.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.735Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = XGBClassifier(objective='binary:logistic',\n",
    "                    learning_rate=0.5,#early_stopping=4,\n",
    "                    use_label_encoder=False,\n",
    "                    scale_pos_weight=4,\n",
    "                    verbosity=0,#min_child_weight=0.8,\n",
    "                    max_depth=6)\n",
    "\n",
    "clf.fit(X_train_reg,y_train,verbose=False,#eval_metric='error',\n",
    "        eval_set=[(X_train_reg,y_train),(X_test_reg, y_test)])\n",
    "\n",
    "ji.evaluate_classification(clf,X_test_reg,y_test,\n",
    "                           X_train=X_train_reg,y_train=y_train,\n",
    "                           label='XGBoost Random Forest');\n",
    "# plt.show()\n",
    "plot_importance(clf,X_test_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost RF Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smoted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.743Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = XGBRFClassifier(learning_rate=0.4,use_label_encoder=False,\n",
    "                      objective='binary:logistic',early_stopping=3,\n",
    "                      scale_pos_weight=2.4,\n",
    "                      max_depth=6)#class_weight='balanced')\n",
    "clf.fit(X_train_reg,y_train)\n",
    "\n",
    "ji.evaluate_classification(clf,X_test_reg,y_test,\n",
    "                           X_train=X_train_reg,y_train=y_train,\n",
    "                           label='XGBoost Random Forest');\n",
    "# plt.show()\n",
    "plot_importance(clf,X_test_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imbalanced Data+scale_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.750Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.utils import compute_class_weight\n",
    "# classes = np.unique(y_train)\n",
    "# weights= dict(zip(classes,compute_class_weight(class_weight='balanced',classes=classes,\n",
    "#                           y=y_train)))\n",
    "# weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.755Z"
    }
   },
   "outputs": [],
   "source": [
    "# clf = XGBRFClassifier(scale_pos_weight=2.3)#class_weight='balanced')\n",
    "# clf.fit(X_train_reg,y_train)\n",
    "\n",
    "# ji.evaluate_classification(clf,X_test_reg,y_test,\n",
    "#                            X_train=X_train_reg,y_train=y_train,\n",
    "#                            label='XGBoost Random Forest');\n",
    "# # plt.show()\n",
    "# plot_importance(clf,X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.760Z"
    }
   },
   "outputs": [],
   "source": [
    "# clf = XGBRFClassifier(scale_pos_weight=2.3)#class_weight='balanced')\n",
    "# clf.fit(X_train_reg,y_train)\n",
    "\n",
    "# ji.evaluate_classification(clf,X_test_reg,y_test,\n",
    "#                            X_train=X_train_reg,y_train=y_train,\n",
    "#                            label='XGBoost Random Forest');\n",
    "# # plt.show()\n",
    "# plot_importance(clf,X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.765Z"
    }
   },
   "outputs": [],
   "source": [
    "# np.linspace(1.8,4.0,num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.769Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# clf = XGBClassifier(scale_pos_rate=2.1,use_label_encoder=False)\n",
    "# params ={'learning_rate':[1,0.1,0.3,0.5],\n",
    "         \n",
    "# #          'scale_pos_rate':np.linspace(1.8,4.0,num=10),\n",
    "# #          'n_estimators':[100,50,200,25],\n",
    "#          'max_depth':[4,5,6],\n",
    "# #          'subsample':[0.8,0.7,0.9,0.6,0.5],\n",
    "# #         'reg_lambda' :[1e-05,1e-04,1e-02,.1,1,10]\n",
    "#          'eval_'\n",
    "#         }\n",
    "\n",
    "\n",
    "# grid = GridSearchCV(clf, params, cv=3,scoring='recall_macro')\n",
    "# grid.fit(X_train_reg,y_train)\n",
    "\n",
    "\n",
    "# print(grid.best_params_)\n",
    "# print(grid.best_score_)\n",
    "# ji.evaluate_classification(grid.best_estimator_,X_test_reg,y_test,\n",
    "#                            X_train=X_train_reg,y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOOKMARK 07/18/21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.779Z"
    }
   },
   "outputs": [],
   "source": [
    "# from tqdm.contrib import tenumerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.783Z"
    }
   },
   "outputs": [],
   "source": [
    "# clf = XGBRFClassifier(n_estimators=100)\n",
    "# params ={'learning_rate':[10,1,0.1,0.01,0.5],\n",
    "#          'n_estimators':[100,50,200,25],\n",
    "#          'subsample':[0.8,0.7,0.9,0.6,0.5],\n",
    "#         'reg_lambda' :[1e-05,1e-04,1e-02,.1,1,10]}\n",
    "\n",
    "\n",
    "# if RUN_SEARCHES:\n",
    "    \n",
    "\n",
    "#     # scores =['recall','recall_macro','accuracy']\n",
    "\n",
    "#     GRIDS={}\n",
    "\n",
    "#     ## Build loop to make dict of grids for each score method\n",
    "#     scores =['f1','f1_macro','roc_auc','recall','recall_macro']#,'accuracy','precision']\n",
    "\n",
    "#     reports = {}\n",
    "#     for _,score in tenumerate(scores):\n",
    "#         line = '==='*30\n",
    "#         print(line)\n",
    "#         print(f'[i] Starting {score}',end='\\n'+line+\"\\n\")\n",
    "\n",
    "#         GRIDS[score] = GridSearchCV(clf,params,cv=3,\n",
    "#                                     scoring=score,\n",
    "#                                     verbose=True,\n",
    "#                                     n_jobs=-1)\n",
    "#         GRIDS[score].fit(X_train_reg_smote,y_train_reg_smote)\n",
    "\n",
    "#         print(f\"\\n[i] Best Params for scoring={score}:\" )\n",
    "#         print(GRIDS[score].best_params_)\n",
    "#         print('\\n\\n')\n",
    "\n",
    "#         reports[score] = ji.evaluate_classification( \n",
    "#             GRIDS[score].best_estimator_,\n",
    "#             X_test_reg,y_test,label=score, \n",
    "#             X_train=X_train_reg_smote, y_train=y_train_reg_smote,return_report=True)\n",
    "#         print('\\n\\n')\n",
    "#         ## Adding best_params to reports\n",
    "#     #     reports[score]['best_params'] = GRIDS[score].best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "clf = SVC(kernel='rbf',max_iter=5000,class_weight='balanced')\n",
    "clf.fit(X_train_reg,y_train)\n",
    "\n",
    "ji.evaluate_classification(clf,X_test_reg,y_test,\n",
    "                           X_train=X_train_reg,y_train=y_train,\n",
    "                           label='LinearSVC');\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.788Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_reg = pd.DataFrame(scaler.fit_transform(X_train_tf),\n",
    "                           columns=X_train_tf.columns, index=X_train_tf.index)\n",
    "X_test_reg = pd.DataFrame(scaler.transform(X_test_tf),\n",
    "                          columns=X_train_tf.columns, index=X_test_tf.index)\n",
    "X_train_reg.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.792Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC,SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.796Z"
    }
   },
   "outputs": [],
   "source": [
    "## smoted data\n",
    "clf = SVC(kernel='rbf',max_iter=5000,verbose=True)#,class_weight='balanced')\n",
    "clf.fit(X_train_reg_smote,y_train_reg_smote)\n",
    "\n",
    "ji.evaluate_classification(clf,X_test_reg,y_test,\n",
    "                           X_train=X_train_reg_smote,y_train=y_train_reg_smote,\n",
    "                           label='SVC');\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.800Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf',max_iter=5000,verbose=True,class_weight='balanced')\n",
    "clf.fit(X_train_reg,y_train)\n",
    "\n",
    "ji.evaluate_classification(clf,X_test_reg,y_test,\n",
    "                           X_train=X_train_reg,y_train=y_train,\n",
    "                           label='SVC');\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.804Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train_reg_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.808Z"
    }
   },
   "outputs": [],
   "source": [
    "np.linspace(0,1,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.812Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## SVC GridSearch\n",
    "clf = SVC(kernel='rbf',max_iter=10000,verbose=True,class_weight='balanced')\n",
    "\n",
    "\n",
    "params = {'C':[0.01,0.1,1.,10,100,1e6,1e12],\n",
    "          'gamma':['scale','auto',*np.linspace(0.00,1,20)],\n",
    "          'class_weight':['balanced','balanced_subsample'],\n",
    "#           'shrinking':[True,False]\n",
    "         }\n",
    "\n",
    "grid = GridSearchCV(clf,params,scoring='recall_macro', cv=3,\n",
    "                    n_jobs=-1,verbose=True)\n",
    "grid.fit(X_train_reg,y_train)\n",
    "print(grid.best_params_)\n",
    "ji.evaluate_classification(grid.best_estimator_,X_test_reg,y_test,\n",
    "                           X_train=X_train_reg,y_train=y_train,\n",
    "                           label='SVC');\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.817Z"
    }
   },
   "outputs": [],
   "source": [
    "# raise Exception(\"Stop here!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Grid Results for Different Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.823Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.contrib import tenumerate\n",
    "# tenumerate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.827Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# if RUN_SEARCHES:\n",
    "#     # scores =['recall','recall_macro','accuracy']\n",
    "\n",
    "#     GRIDS={}\n",
    "\n",
    "#     ## Build loop to make dict of grids for each score method\n",
    "#     scores =['f1','f1_macro','roc_auc','recall','recall_macro']#,'accuracy','precision']\n",
    "\n",
    "#     reports = {}\n",
    "#     for _,score in tenumerate(scores):\n",
    "#         line = '==='*30\n",
    "#         print(line)\n",
    "#         print(f'[i] Starting {score}',end='\\n'+line+\"\\n\")\n",
    "\n",
    "#         GRIDS[score] = GridSearchCV(clf,params,cv=3,\n",
    "#                                     scoring=score,\n",
    "#                                     verbose=True,\n",
    "#                                     n_jobs=-1)\n",
    "#         GRIDS[score].fit(X_train_smote,y_train_smote)\n",
    "\n",
    "#         print(f\"\\n[i] Best Params for scoring={score}:\" )\n",
    "#         print(GRIDS[score].best_params_)\n",
    "#         print('\\n\\n')\n",
    "\n",
    "#         reports[score] = ji.evaluate_classification( \n",
    "#             GRIDS[score].best_estimator_,\n",
    "#             X_test_tf,y_test,label=score, \n",
    "#             X_train=X_train_smote, y_train=y_train_smote,return_report=True)\n",
    "#         print('\\n\\n')\n",
    "#         ## Adding best_params to reports\n",
    "#     #     reports[score]['best_params'] = GRIDS[score].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.832Z"
    }
   },
   "outputs": [],
   "source": [
    "# pd.concat(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.837Z"
    }
   },
   "outputs": [],
   "source": [
    "# if RUN_SEARCHES:\n",
    "#     dfs=[]\n",
    "#     for metric,result in reports.items():\n",
    "\n",
    "#         result['scoring_param'] = metric\n",
    "#         dfs.append(pd.DataFrame(result))\n",
    "\n",
    "#     RESULTS = pd.concat(dfs).reset_index().set_index(['scoring_param','index'])\n",
    "#     # RESULTS.drop('scoring param',inplace=True)\n",
    "#     RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.842Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train_smote.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.846Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# X_train_logreg = scaler.fit_transform(X_train_smote)\n",
    "# X_test_logreg = scaler.transform(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.850Z"
    }
   },
   "outputs": [],
   "source": [
    "logregCV = LogisticRegressionCV( scoring='recall',n_jobs=-1,verbose=True)#,penalty='l1',cv=3,\n",
    "#                                 solver='liblinear',max_iter=250,n_jobs=-1)\n",
    "\n",
    "logregCV.fit(X_train_reg_smote,y_train_reg_smote)\n",
    "logregCV.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.855Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ji.evaluate_classification(logregCV,X_test_reg,y_test,  \n",
    "                           X_train=X_train_reg_smote,y_train=y_train_reg_smote,\n",
    "                           label='Logistic Regression CV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.859Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train_reg_smote,y_train_reg_smote)\n",
    "\n",
    "ji.evaluate_classification(clf,X_test_reg,y_test,\n",
    "                           X_train=X_train_reg_smote,y_train=y_train_reg_smote,\n",
    "                           label='LinearSVC');\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.863Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {'n_neighbors':[3,4,5,7],\n",
    "          'p':[1,2]\n",
    "         }\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "\n",
    "\n",
    "grid = GridSearchCV(clf,params,scoring='f1', cv=3,\n",
    "                    n_jobs=-1,verbose=True)\n",
    "grid.fit(X_train_reg_smote,y_train_reg_smote)\n",
    "\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "ji.evaluate_classification(grid.best_estimator_,X_test_reg,y_test,\n",
    "                           X_train=X_train_reg_smote,y_train=y_train_reg_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.866Z"
    }
   },
   "outputs": [],
   "source": [
    "# def get_coeffs(logregCV, X_train_smote,):\n",
    "#     coeffs = pd.Series(logregCV.coef_[0],index=X_train_smote.columns)\n",
    "#     coeffs['Intercept'] = logregCV.intercept_\n",
    "#     coeffs = coeffs.astype(float)\n",
    "#     return coeffs\n",
    "\n",
    "# coeffs = get_coeffs(logregCV,X_train_smote)\n",
    "# coeffs.sort_values().plot(kind='barh',figsize=(5,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.870Z"
    }
   },
   "outputs": [],
   "source": [
    "# logregCV.C_, logregCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.875Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_tf.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.879Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Import catboost Pool to create training and testing pools\n",
    "# from catboost import Pool, CatBoostClassifier\n",
    "\n",
    "# # train_pool =  Pool(data=X_train_tf.astype(int), label=y_train, cat_features=[int(i) for i in cat_col_index])\n",
    "# # test_pool = Pool(data=X_test_tf.astype(int), label=y_test,  cat_features=[int(i) for i in cat_col_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.882Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Instantiating CatBoostClassifier \n",
    "# cb_base = CatBoostClassifier(\n",
    "#     iterations=2000,#depth=12,\n",
    "#     boosting_type='Ordered',\n",
    "#     learning_rate=0.001,\n",
    "#     thread_count=-1,\n",
    "#     eval_metric='Recall',\n",
    "#     silent=True,\n",
    "#     allow_const_label=True\n",
    "# )#,|\n",
    "# cb_base.fit(X_train_reg_smote, y_train_reg_smote, plot=True, early_stopping_rounds=50)\n",
    "# cb_base.best_score_\n",
    "\n",
    "# ji.evaluate_classification(cb_base,X_test_reg,y_test, \n",
    "#                           X_train=X_train_reg_smote,y_train=y_train_reg_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.886Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Instantiating CatBoostClassifier \n",
    "# cb_base = CatBoostClassifier(iterations=1000, depth=14,\n",
    "#                             boosting_type='Ordered',\n",
    "#                             learning_rate=0.03,\n",
    "#                             thread_count=-1,\n",
    "#                             eval_metric='AUC',\n",
    "#                              silent=True,\n",
    "#                             allow_const_label=True\n",
    "# )#,\n",
    "# cb_base.fit(X_train_reg_smote, y_train_reg_smote, plot=True, early_stopping_rounds=30)\n",
    "# cb_base.best_score_\n",
    "\n",
    "# ji.evaluate_classification(cb_base,X_test_reg,y_test, \n",
    "#                           X_train=X_train_reg_smote,y_train=y_train_reg_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.890Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Instantiating CatBoostClassifier \n",
    "# cb_base = CatBoostClassifier(iterations=3000, depth=14,\n",
    "#                             boosting_type='Ordered',\n",
    "#                             learning_rate=0.01,\n",
    "#                             thread_count=-1,\n",
    "#                             eval_metric='AUC',\n",
    "#                              silent=True,\n",
    "#                             allow_const_label=True\n",
    "# )#,\n",
    "# cb_base.fit(X_train_reg_smote, y_train_reg_smote, plot=True, early_stopping_rounds=30)\n",
    "# cb_base.best_score_\n",
    "\n",
    "# ji.evaluate_classification(cb_base,X_test_reg,y_test, \n",
    "#                           X_train=X_train_reg_smote,y_train=y_train_reg_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.894Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Instantiating CatBoostClassifier \n",
    "# #,\n",
    "                        \n",
    "# cb_orig = CatBoostClassifier(iterations=3000, depth=4,\n",
    "#                             boosting_type='Ordered',\n",
    "#                             learning_rate=0.03,\n",
    "#                             thread_count=-1,\n",
    "#                             eval_metric='AUC',\n",
    "#                             allow_const_label=True,\n",
    "#                            silent=True)\n",
    "# cb_orig.fit(X_train_reg_smote, y_train_reg_smote, plot=True, early_stopping_rounds=30)\n",
    "# print(cb_orig.best_score_)\n",
    "\n",
    "# ji.evaluate_classification(cb_orig,X_test_reg,y_test, \n",
    "#                           X_train=X_train_reg_smote,y_train=y_train_reg_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSIONS\n",
    "- **After adjusting for imbalanced classes, the most important factor for determining recidivism are:**\n",
    "    - **Age at Release**\n",
    "    - **Supervising Judicial District**\n",
    "    - **Release Type**\n",
    "    - **Crime Subtype**\n",
    "    \n",
    "    \n",
    "## Recommendatons\n",
    "- This model could be used to predict which prisoners due for release may at the greatest risk for recidivism.<br><br>\n",
    "    - Using this knowledge, the state of Iowa could put new programs into action that target those at high risk for recidivism and provide additional assistance and guidance following release.<br><br>\n",
    "    - Additionally, there could be additional counseling or education _prior_ to release to supply the inmate with tools and options to avoid returning to a life of crime.\n",
    "    \n",
    "# FUTURE DIRECTIONS\n",
    "- With more time and reliable performance, would perform cross-validation of our final model.<br><br>\n",
    "- Additional visuals summarizing the underlying features effects on recidivism.<br><br>\n",
    "- Adapting more available visualization tools to better display the underpinning of the model.\n",
    "<br><br>\n",
    "- Exploration of the predictability of crimes types committed by recidivists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POST-REVIEW SUGGESTIONS / IDEAS:\n",
    "- [ ] Try using reduction instead of SMOTE.\n",
    "- [ ] seaborn catplot bar graphs\n",
    "- [ ] Add tree or other visuals\n",
    "    - Try Mike's SHAP plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T17:28:50.840094Z",
     "start_time": "2020-10-06T17:28:50.836840Z"
    }
   },
   "source": [
    "## Bookmark: saving gridsearch\n",
    "https://stackabuse.com/scikit-learn-save-and-restore-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.900Z"
    }
   },
   "outputs": [],
   "source": [
    "## Make a folder for saving models\n",
    "import os\n",
    "mpath = './models/'\n",
    "os.makedirs(mpath,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.904Z"
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "## Save Grid\n",
    "joblib_file = mpath+'rf_gridsearch_recall_macro.pkl'\n",
    "joblib.dump(grid,joblib_file,compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.907Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_loaded = joblib.load(joblib_file)\n",
    "grid_loaded.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.911Z"
    }
   },
   "outputs": [],
   "source": [
    "# STOP\n",
    "\n",
    "# from bs_ds import viz_tree\n",
    "\n",
    "# viz_tree(cb_clf)\n",
    "\n",
    "\n",
    "\n",
    "# compare_tree = sklearn.tree.DecisionTreeClassifier()\n",
    "# dir(compare_tree)\n",
    "\n",
    "# compare_tree.fit(X_train, y_train)\n",
    "\n",
    "# dir(compare_tree)\n",
    "\n",
    "# # This is the tree object that sklearn generates and is looking for \n",
    "# help(compare_tree.tree_)\n",
    "\n",
    "# dir(cb_clf)\n",
    "\n",
    "# help(cb_clf.get_metadata())\n",
    "\n",
    "# test = cb_clf.get_metadata()\n",
    "\n",
    "# help(cb_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP values\n",
    "https://github.com/jirvingphd/shap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SHAP and Shapely Values for Model Interpretation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- White Paper on Shapely Values:\n",
    "    - https://arxiv.org/abs/1705.07874\n",
    "    \n",
    "- Blog Posts:\n",
    "    - https://towardsdatascience.com/explain-your-model-with-the-shap-values-bc36aac4de3d\n",
    "\n",
    "    - https://towardsdatascience.com/explain-any-models-with-the-shap-values-use-the-kernelexplainer-79de9464897a\n",
    "\n",
    "\n",
    "- Videos/Talks:\n",
    "    - [\"Open the Black Box: an intro to Model Interpretability with LIME and SHAP](https://youtu.be/C80SQe16Rao)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Uses game theory to explain feature importance and how a feature steered a model's prediction(s) by removing each feature and seeing the effect on the error.\n",
    "\n",
    "- SHAP has:\n",
    "    - `TreeExplainer`:\n",
    "        - compatible with sckit learn, xgboost, Catboost\n",
    "    - `KernelExplainer`:\n",
    "        - compatible with \"any\" model\n",
    "        \n",
    "\n",
    "\n",
    "- See [this blog post](https://towardsdatascience.com/explain-your-model-with-the-shap-values-bc36aac4de3d) for intro to topic and how to use with trees\n",
    "\n",
    "- For non-tree/random forest models [see this follow up post]( https://towardsdatascience.com/explain-any-models-with-the-shap-values-use-the-kernelexplainer-79de9464897a)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Get Expanations for Trees:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Import and initialize javascript:\n",
    "\n",
    "```python\n",
    "import shap \n",
    "shap.initjs()\n",
    "```\n",
    "1. Create a shap explainer using your fit model.\n",
    "\n",
    "```python\n",
    "explainer = shap.TreeExplainer(xgb_clf)\n",
    "```\n",
    "\n",
    "2. Get shapely values from explainer for your training data\n",
    "\n",
    "```python\n",
    "shap_values = explainer.shap_values(X_train,y_train)\n",
    "```            \n",
    "\n",
    "3. Select which type of the available plots you'd like to visualize\n",
    "\n",
    "    \n",
    "- **Types of Plots:**\n",
    "    - `summary_plot()`\n",
    "    - `dependence_plot()`\n",
    "    - `force_plot()` for a given observation\n",
    "    - `force_plot()` for all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "## For normal bar graph of importance:\n",
    "shap.summary_plot(shap_values,X_train,plot_type='bar')\n",
    "\n",
    "## For detail Shapely value visuals:\n",
    "shap.summary_plot(shap_values, X_train)\n",
    "```\n",
    "\n",
    "**`shap.summary_plot`**\n",
    "> - Feature importance: Variables are ranked in descending order.\n",
    "- Impact: The horizontal location shows whether the effect of that value is associated with a higher or lower prediction.\n",
    "- Original value: Color shows whether that variable is high (in red) or low (in blue) for that observation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`shap.dependence_plot`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "## To Auto-Select Feature Most correlated with a specific feature, just pass the desired feature's column name.\n",
    "\n",
    "shap.dependence_plot('super_dist', shap_values, X_train)\n",
    "\n",
    "## There is a way to specifically call out multiple features but I wasn't able to summarize it quickly for this nb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`shap.force_plot`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show an individual data point's prediction and the factors pushing it towards one class or another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "## Just using np to randomly select a row\n",
    "\n",
    "row = np.random.choice(range(len(X_train))\n",
    "                       \n",
    "shap.force_plot(explainer.expected_value, shap_values[row,:], X_train.iloc[row,:])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.925Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = grid.best_estimator_\n",
    "\n",
    "evaluate_classification(clf, X_test_tf,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.929Z"
    }
   },
   "outputs": [],
   "source": [
    "# %conda list shap\n",
    "\n",
    "# !pip install -U shap\n",
    "\n",
    "# %conda uninstall shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.933Z"
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.938Z"
    }
   },
   "outputs": [],
   "source": [
    "shap.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.942Z"
    }
   },
   "outputs": [],
   "source": [
    "X_shap = shap.sample(X_test_tf)\n",
    "X_shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.946Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.style.use('seaborn-notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.950Z"
    }
   },
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.954Z"
    }
   },
   "outputs": [],
   "source": [
    "shap_vals = explainer.shap_values(X_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.958Z"
    }
   },
   "outputs": [],
   "source": [
    "shap_ixn_vals = explainer.shap_interaction_values(X_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.963Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "shap.summary_plot(shap_vals, X_shap,plot_type='dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.966Z"
    }
   },
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, X_shap[:1000],X_train[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-07T18:35:50.970Z"
    }
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_vals, X_train, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env-new",
   "language": "python",
   "name": "learn-env-new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.156px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 572.166222,
   "position": {
    "height": "593.931px",
    "left": "841.588px",
    "right": "20px",
    "top": "77px",
    "width": "705.306px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
